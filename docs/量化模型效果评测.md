# Qwen3-VL-8B-Instruct AWQ 量化模型效果评测

本文档对量化后的 `Qwen3-VL-8B-Instruct-AWQ` 模型进行了详细的规格对比与能力评测，旨在验证 AWQ INT4 量化在大幅降低资源消耗的同时，是否保留了核心的多模态理解能力。

## 1. 模型规格对比

| 指标 | 原始模型 (Original) | 量化模型 (AWQ) | 变化幅度 |
| :--- | :--- | :--- | :--- |
| **精度** | BF16 (16-bit) | INT4 (4-bit) | - |
| **磁盘占用** | ~16.5 GB | **6.8 GB** | 📉 减少约 59% |
| **文件结构** | 4 个分片 (.safetensors) | 2 个分片 (.safetensors) | 更利于管理 |
| **显存需求 (推理)** | > 16 GB (甚至更高) | **~7.5 GB** | 可在 8G-12G 显存运行 |

**结论**：量化后的模型体积缩小至原来的 **41%**，使得该 8B 模型可以轻松部署在单张消费级显卡（如 RTX 3080, 4070, 甚至 3060 12G）上，极大降低了部署门槛。

## 2. OCRBench 评测结果

我们使用 **OCRBench** 数据集（包含 1000 个 OCR 相关问题）对量化模型进行了完整测试。该基准测试涵盖了场景文本识别、文档理解等核心视觉能力。

### 2.1 总体表现

*   **总样本数**: 1000
*   **正确数量**: 874
*   **总体准确率**: **87.40%**

### 2.2 分段统计详情

为了观察模型表现的稳定性，我们对 1000 个样本进行了分段统计（每 100 个样本）：

| 样本区间 (Range) | 正确数/总数 | 准确率 (Batch Accuracy) |
| :--- | :--- | :--- |
| 1 - 100 | 98/100 | **98.00%** |
| 101 - 200 | 93/100 | 93.00% |
| 201 - 300 | 86/100 | 86.00% |
| 301 - 400 | 81/100 | 81.00% |
| 401 - 500 | 94/100 | 94.00% |
| 501 - 600 | 83/100 | 83.00% |
| 601 - 700 | 79/100 | 79.00% |
| 701 - 800 | 89/100 | 89.00% |
| 801 - 900 | 91/100 | 91.00% |
| 901 - 1000 | 80/100 | 80.00% |

**分析**：
*   **极高上限**：在部分批次（如前 100 条）中，模型达到了惊人的 98% 准确率，说明其基础 OCR 识别能力非常扎实。
*   **稳定性**：虽然在某些复杂样本区间（如 601-700）准确率有所波动（最低 79%），但整体始终维持在较高水平，未出现灾难性遗忘或能力崩塌。

### 2.3 样例分析
*   **优势**: 对于标准印刷体、单词识别（如 "CENTRE", "FRIEND"），模型识别精准，几乎没有偏差。
*   **不足**: 在极少数模糊图像或手写体识别上（如 "Scottynn" 误读为 "scottlynn"），可能会出现细微的字符级错误或幻觉。

## 3. 综合评价

本次量化实验非常成功。`Qwen3-VL-8B-Instruct-AWQ` 在将显存和存储需求**减半**的情况下，依然在 OCRBench 上取得了 **87.4%** 的高分。

这证明了我们在量化过程中采用的策略（**保护 Visual Encoder 不被量化**，仅量化 LLM 部分）是非常有效的。该模型完全具备在资源受限的边缘设备或个人工作站上处理高质量多模态任务的能力。
